---
title: "Dec 5 Lab - regression assumptions and multiple regression"
author: "Suyog Chandramouli"
date: "2024-12-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The focus of this lab is on evaluating data to check if linear regression assumptions are being met and fitting a multiple regression model to data.

We'll be working with the 'Parenthood' dataset, created by Dr. Danielle Navarro, which presents an interesting application of multiple regression. 

The dataset captures 100 days of supposed observations of sleep patterns and mood. She quantified her daily grumpiness on a scale ranging from 0 (not at all grumpy) to 100 (extremely grumpy).

Each day, she recorded three key variables:
her grumpiness level,
the amount of sleep she got, and
the amount of sleep her infant son got.


First, let's load the data
```{r}
load("parenthood.Rdata")
names(parenthood)<- c("dan.sleep", "baby.sleep", "dan.grump", "day")
head(parenthood)
```
To get a good idea of the dataset, it's worth visualizing it using multiple scatterplots.
```{r}

```


One possible explanation of Danielle's grumpiness is that it is influence by the amount of sleep she has had, and the amount of sleep that her baby has had. What would be a simple multiple regression model that captures this? Define and fit it to the data with lm()

(Hint: 2 predictors)
```{r}

```
Having fit the model to the data, we now have access to both, the fitted values and the residuals. This means that the regression assumptions can also be assessed :)

Use the model check function from the performance package to assess model assumptions visually.
It takes as input the fitted model and the list of tests.
Only giving the model as input however produces a more exhaustive lists of checks. 
```{r}
library(performance)

#Insert code
```
What do you observe? For any explanations of the observations make sure that you mention it in terms of the variables on the x and y axes of the plots that are generated. 
```{r}
#Add text
```

Note that while these visual model checks give you a qualitative idea of whether the assumptions are met, each of the regression assumptions also has corresponding quantitative tests. These tests are often based on appropriate hypotheses tests that are relevant for a given assumption. 

E.g. a test for normality of residuals could be based on the null hypothesis that the residuals are indeed normal. But this gets rejected if the p-value generated by the test is lesser than our threshold (e.g. < 0.05). This is in fact the "Shapiro-Wilk test". 

Run the shapiro test for normality of residuals. 
shapiro.test() takes as input the residuals of your model which can be found via the residuals() function or via relevant functions if you are using broom. 

```{r}

```
What is the outcome of the Shapiro-Wilk normality test? Does it match you assessment (for normality) from the visual model check?

```{r}
#Add text
```

Similarly the Breusch-Pagan test -- bptest() in the lmtest package, checks for the assumption of constant variance. Carry it out and see if it matches your assessment from the visual model check 

```{r}

```

The point to note is that there are several tests for testing assumptions as well, and sometimes the test you may want to use will depend on your modeling scenario.  
---

Bonus Question: If the underlying research question Navarro intended to explore was whether her son's sleep patterns had any significant relationship with her grumpiness, beyond what could be explained by her own sleep patterns,how would you think of solving this question?

(Hint: this question suggests that she is thinking of two different models of the data generating process)

```{r}
#Answer in text.
```

Having done this lab, I encourage you to go through chapter 15 of Learning Statistics with R in more detail, as it talks about many more modeling nuances. 